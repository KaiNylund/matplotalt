{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from collections import defaultdict\n",
    "from matplotalt import *\n",
    "from matplotalt_helpers import pillow_image_to_base64_string\n",
    "from PIL import Image\n",
    "from api_helpers import get_openai_vision_response\n",
    "\n",
    "alt_figs_path = \"./alt_figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203\n"
     ]
    }
   ],
   "source": [
    "fig_ids = []\n",
    "for alt_cap_path in os.listdir(alt_figs_path):\n",
    "    if alt_cap_path.endswith(\".txt\"):\n",
    "        fig_ids.append(alt_cap_path.split(\".\")[0][3:])\n",
    "\n",
    "print(len(fig_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 70/203 [15:49<28:49, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 116/203 [37:08<18:28, 12.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 203/203 [57:26<00:00, 16.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 201\n",
      "Num errors: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_id_to_captions = []\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "desc_level_prompt = get_desc_level_prompt(desc_level=3)\n",
    "for fig_id in tqdm(fig_ids):\n",
    "    try:\n",
    "        fig_caption_dict = {\"figure_id\": fig_id}\n",
    "        starter_alt = None\n",
    "        # Get text caption\n",
    "        with open(f\"{alt_figs_path}/nb_{fig_id}.txt\") as heuristic_cap_file:\n",
    "            starter_alt = heuristic_cap_file.read()\n",
    "            fig_caption_dict[\"heuristic\"] = starter_alt\n",
    "        # Get figure image in base64\n",
    "        pil_img = Image.open(f\"{alt_figs_path}/nb_{fig_id}.jpg\")\n",
    "        base64_img = pillow_image_to_base64_string(pil_img)\n",
    "\n",
    "        #print(desc_level_prompt)\n",
    "        #print(starter_alt)\n",
    "        # gpt4-turbo\n",
    "        gpt4_caption = get_openai_vision_response(OPENAI_API_KEY, desc_level_prompt, base64_img, model=model, use_azure=True, max_tokens=225, return_full_response=False)\n",
    "        fig_caption_dict[\"gpt-4-turbo-L3-225\"] = gpt4_caption\n",
    "        # gpt4-turbo + starter alt\n",
    "        if starter_alt is not None:\n",
    "            starter_alt_prompt = get_desc_level_prompt(desc_level=3, starter_desc=starter_alt)\n",
    "            gpt4_alt_caption = get_openai_vision_response(OPENAI_API_KEY, starter_alt_prompt, base64_img, model=model, use_azure=True, max_tokens=225, return_full_response=False)\n",
    "            fig_caption_dict[\"gpt-4-turbo-alt-L3-225\"] = gpt4_alt_caption\n",
    "        plt.clf()\n",
    "        fig_id_to_captions.append(fig_caption_dict)\n",
    "        #pprint(fig_id_to_captions)\n",
    "        np.save(\"./fig_id_captions_arr3\", fig_id_to_captions)\n",
    "        n_passed += 1\n",
    "    except Exception as e:\n",
    "        #raise e\n",
    "        print(fig_id)\n",
    "        n_errors += 1\n",
    "        plt.clf()\n",
    "        print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")\n",
    "combined_captions_df = pd.DataFrame.from_dict(fig_id_to_captions)\n",
    "combined_captions_df.to_json(\"./mpl_gallery_combined_captions3.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_captions_df = pd.read_json(\"./mpl_gallery_combined_captions.jsonl\", orient=\"records\", lines=True)\n",
    "combined_captions_df = combined_captions_df.sample(frac=1.0)\n",
    "combined_captions_df.to_json(\"./mpl_gallery_combined_captions_shuffled.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      367\n",
      "1      337\n",
      "2      383\n",
      "3      362\n",
      "4       73\n",
      "      ... \n",
      "196    346\n",
      "197    244\n",
      "198    181\n",
      "199    446\n",
      "200    116\n",
      "Name: figure_id, Length: 201, dtype: object\n",
      "Index(['heuristic', 'gpt-4-turbo-L3-225', 'gpt-4-turbo-alt-L3-225',\n",
      "       'figure_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "shuffled_captions_df = pd.read_json(\"./mpl_gallery_combined_captions_shuffled_old.jsonl\", orient=\"records\", lines=True)\n",
    "new_captions_df = pd.read_json(\"./mpl_gallery_combined_captions3.jsonl\", orient=\"records\", lines=True)\n",
    "\n",
    "original_fig_ids = shuffled_captions_df[\"figure_id\"]\n",
    "\n",
    "combined_shuffled_df = shuffled_captions_df.reset_index().merge(new_captions_df, how=\"left\").set_index('figure_id')\n",
    "combined_shuffled_df = combined_shuffled_df.drop(columns=[\"gpt-4-turbo-L4-300\", \"gpt-4-turbo-alt-L4-300\", \"index\"])\n",
    "combined_shuffled_df.reset_index()\n",
    "print(original_fig_ids)\n",
    "combined_shuffled_df[\"figure_id\"] = combined_shuffled_df.index\n",
    "print(combined_shuffled_df.columns)\n",
    "combined_shuffled_df.to_json(\"./mpl_gallery_combined_captions_shuffled.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
