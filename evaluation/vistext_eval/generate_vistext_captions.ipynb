{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from matplotalt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "1265    None\n",
       "1266    None\n",
       "1267    None\n",
       "1268    None\n",
       "1269    None\n",
       "Length: 1270, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vistext_id_to_mpl_code = np.load(\"./vistext_id_to_mpl_code.npy\", allow_pickle=True).item()\n",
    "vistext_val_data = pd.read_json(\"./vistext_data_test.json\")\n",
    "#vistext_dev_data = pd.read_json(\"./vistext_data_validation.json\")\n",
    "#vistext_train_data = pd.read_json(\"./vistext_data_train.json\")\n",
    "vistext_id_to_captions = defaultdict(list)\n",
    "vistext_id_to_chart_type = {}\n",
    "def get_id_to_captions(row):\n",
    "    vistext_id_to_captions[row[\"img_id\"]].append({\"L1\": row[\"caption_L1\"], \"L2L3\": row[\"caption_L2L3\"]})\n",
    "    vistext_id_to_chart_type[row[\"img_id\"]] = row[\"L1_properties\"][0]\n",
    "\n",
    "vistext_val_data.apply(get_id_to_captions, axis=1)\n",
    "#vistext_dev_data.apply(get_id_to_captions, axis=1)\n",
    "#vistext_train_data.apply(get_id_to_captions, axis=1)\n",
    "#np.save(\"./vistext_test_id_to_captions\", vistext_id_to_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:41<00:00, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 882\n",
      "Num errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(len(vistext_id_to_captions))\n",
    "n_passed = 0\n",
    "n_errors = 0\n",
    "#vistext_id_to_captions = np.load(\"./evaluation/vistext_to_mpl/vistext_id_to_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_matplotalt_captions = {}\n",
    "for chart_id in tqdm(vistext_id_to_captions.keys()):\n",
    "    #print(vistext_id_to_mpl_code.keys())\n",
    "    try:\n",
    "        plt.clf()\n",
    "        mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "        chart_type = vistext_id_to_chart_type[chart_id]\n",
    "        exec(mpl_code)\n",
    "        #print(chart_id)\n",
    "        #print(mpl_code)\n",
    "        #plt.show()\n",
    "        #plt.gcf().savefig(f\"./matplotlib_ver_imgs/{chart_id}.png\", bbox_inches='tight')\n",
    "        # Only include min and max stats as others (like linear fit, std rarely or do not occur in vistext captions)\n",
    "        # Also exclude color descriptions since they are different in the matplotlib version of vistext figures\n",
    "        matplotalt_caption = show_with_alt(desc_level=3, methods=[], stats=[\"min\", \"max\"], max_color_desc_count=0, return_alt=True)\n",
    "        vistext_id_to_matplotalt_captions[chart_id] = matplotalt_caption\n",
    "        n_passed += 1\n",
    "    except Exception as e:\n",
    "        #raise e\n",
    "        print(chart_id)\n",
    "        print(mpl_code)\n",
    "        n_errors += 1\n",
    "        print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")\n",
    "np.save(\"./vistext_test_id_to_matplotalt_captions\", vistext_id_to_matplotalt_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 754/882 [00:07<00:01, 105.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:13<00:00, 67.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 2\n",
      "Num errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_captions = np.load(\"./vistext_test_id_to_L3_gpt4_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_captions:\n",
    "        print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                            desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                            use_starter_alt_in_prompt=False, use_azure=True,\n",
    "                                            include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_captions[chart_id] = gpt4_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_captions\", vistext_id_to_gpt4_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 490/882 [1:06:46<1:06:09, 10.13s/it]C:\\Users\\Kai\\Desktop\\matplotalt\\matplotalt\\matplotalt.py:538: UserWarning: Glyph 144 (\\x90) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      " 83%|████████▎ | 731/882 [1:36:10<14:32,  5.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [1:55:13<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 881\n",
      "Num errors: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_alt_captions = {} #np.load(\"./vistext_test_id_to_L3_gpt4_alt_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_alt_captions:\n",
    "        #print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_alt_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=True, use_azure=True,\n",
    "                                        include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_alt_captions[chart_id] = gpt4_alt_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_alt_captions\", vistext_id_to_gpt4_alt_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 116/882 [00:00<00:05, 129.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n",
      "1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 131/882 [00:08<01:00, 12.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 237/882 [00:15<00:46, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 375/882 [00:24<00:35, 14.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 378/882 [00:30<00:52,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 400/882 [00:38<01:07,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 731/882 [00:44<00:07, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 754/882 [00:50<00:08, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:57<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 8\n",
      "Num errors: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_table_captions = np.load(\"./vistext_test_id_to_L3_gpt4_table_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_table_captions:\n",
    "        print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_table_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=False, use_azure=True,\n",
    "                                        include_colors=False, include_table=True)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_table_captions[chart_id] = gpt4_table_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_table_captions\", vistext_id_to_gpt4_table_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_table_alt_captions = {} #np.load(\"./vistext_test_id_to_L3_gpt4_table_alt_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_table_alt_captions:\n",
    "        #print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_table_alt_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=True, use_azure=True,\n",
    "                                        include_table_in_prompt=True,\n",
    "                                        include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_table_alt_captions[chart_id] = gpt4_table_alt_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_table_alt_captions\", vistext_id_to_gpt4_table_alt_captions)\n",
    "            n_passed += 1\n",
    "            #print(gpt4_table_alt_caption)\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
