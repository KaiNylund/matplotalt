{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from matplotalt import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "1265    None\n",
       "1266    None\n",
       "1267    None\n",
       "1268    None\n",
       "1269    None\n",
       "Length: 1270, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vistext_id_to_mpl_code = np.load(\"./vistext_id_to_mpl_code.npy\", allow_pickle=True).item()\n",
    "vistext_val_data = pd.read_json(\"./vistext_data_test.json\")\n",
    "#vistext_dev_data = pd.read_json(\"./vistext_data_validation.json\")\n",
    "#vistext_train_data = pd.read_json(\"./vistext_data_train.json\")\n",
    "vistext_id_to_captions = defaultdict(list)\n",
    "vistext_id_to_chart_type = {}\n",
    "def get_id_to_captions(row):\n",
    "    vistext_id_to_captions[row[\"img_id\"]].append({\"L1\": row[\"caption_L1\"], \"L2L3\": row[\"caption_L2L3\"]})\n",
    "    vistext_id_to_chart_type[row[\"img_id\"]] = row[\"L1_properties\"][0]\n",
    "\n",
    "vistext_val_data.apply(get_id_to_captions, axis=1)\n",
    "#vistext_dev_data.apply(get_id_to_captions, axis=1)\n",
    "#vistext_train_data.apply(get_id_to_captions, axis=1)\n",
    "#np.save(\"./vistext_test_id_to_captions\", vistext_id_to_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:41<00:00, 21.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 882\n",
      "Num errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(len(vistext_id_to_captions))\n",
    "n_passed = 0\n",
    "n_errors = 0\n",
    "#vistext_id_to_captions = np.load(\"./evaluation/vistext_to_mpl/vistext_id_to_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_matplotalt_captions = {}\n",
    "for chart_id in tqdm(vistext_id_to_captions.keys()):\n",
    "    #print(vistext_id_to_mpl_code.keys())\n",
    "    try:\n",
    "        plt.clf()\n",
    "        mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "        chart_type = vistext_id_to_chart_type[chart_id]\n",
    "        exec(mpl_code)\n",
    "        #print(chart_id)\n",
    "        #print(mpl_code)\n",
    "        #plt.show()\n",
    "        #plt.gcf().savefig(f\"./matplotlib_ver_imgs/{chart_id}.png\", bbox_inches='tight')\n",
    "        # Only include min and max stats as others (like linear fit, std rarely or do not occur in vistext captions)\n",
    "        # Also exclude color descriptions since they are different in the matplotlib version of vistext figures\n",
    "        matplotalt_caption = show_with_alt(desc_level=3, methods=[], stats=[\"min\", \"max\"], max_color_desc_count=0, return_alt=True)\n",
    "        vistext_id_to_matplotalt_captions[chart_id] = matplotalt_caption\n",
    "        n_passed += 1\n",
    "    except Exception as e:\n",
    "        #raise e\n",
    "        print(chart_id)\n",
    "        print(mpl_code)\n",
    "        n_errors += 1\n",
    "        print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")\n",
    "np.save(\"./vistext_test_id_to_matplotalt_captions\", vistext_id_to_matplotalt_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 754/882 [00:07<00:01, 105.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:13<00:00, 67.20it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 2\n",
      "Num errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_captions = np.load(\"./vistext_test_id_to_L3_gpt4_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_captions:\n",
    "        print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                            desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                            use_starter_alt_in_prompt=False, use_azure=True,\n",
    "                                            include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_captions[chart_id] = gpt4_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_captions\", vistext_id_to_gpt4_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 490/882 [1:06:46<1:06:09, 10.13s/it]C:\\Users\\Kai\\Desktop\\matplotalt\\matplotalt\\matplotalt.py:538: UserWarning: Glyph 144 (\\x90) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      " 83%|████████▎ | 731/882 [1:36:10<14:32,  5.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [1:55:13<00:00,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 881\n",
      "Num errors: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_alt_captions = {} #np.load(\"./vistext_test_id_to_L3_gpt4_alt_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_alt_captions:\n",
    "        #print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_alt_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=True, use_azure=True,\n",
    "                                        include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_alt_captions[chart_id] = gpt4_alt_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_alt_captions\", vistext_id_to_gpt4_alt_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/882 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 116/882 [00:00<00:05, 129.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n",
      "1439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 131/882 [00:08<01:00, 12.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 237/882 [00:15<00:46, 13.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 375/882 [00:24<00:35, 14.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 378/882 [00:30<00:52,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 400/882 [00:38<01:07,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 731/882 [00:44<00:07, 20.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 754/882 [00:50<00:08, 15.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [00:57<00:00, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 8\n",
      "Num errors: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_table_captions = np.load(\"./vistext_test_id_to_L3_gpt4_table_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_table_captions:\n",
    "        print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_table_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=False, use_azure=True,\n",
    "                                        include_colors=False, include_table=True)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_table_captions[chart_id] = gpt4_table_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_table_captions\", vistext_id_to_gpt4_table_captions)\n",
    "            n_passed += 1\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 29/882 [03:41<1:21:47,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 47/882 [05:40<1:05:25,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 156/882 [20:49<1:04:29,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1706\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 184/882 [24:24<1:05:43,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 227/882 [29:26<1:01:28,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2416\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 234/882 [30:04<50:14,  4.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2465\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 305/882 [38:43<53:19,  5.55s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3373\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 349/882 [43:45<51:13,  5.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3762\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 487/882 [1:02:12<42:14,  6.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4982\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 489/882 [1:02:22<36:06,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4992\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 490/882 [1:02:32<44:36,  6.83s/it]C:\\Users\\Kai\\Desktop\\matplotalt\\matplotalt\\matplotalt.py:538: UserWarning: Glyph 144 (\\x90) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.draw()\n",
      " 58%|█████▊    | 508/882 [1:05:15<55:29,  8.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5115\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 583/882 [1:15:07<24:30,  4.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5913\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 617/882 [1:19:37<21:41,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6240\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 697/882 [1:29:46<16:38,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6859\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 731/882 [1:34:20<12:11,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n",
      "Error code: 400 - {'error': {'inner_error': {'code': 'ResponsibleAIPolicyViolation', 'content_filter_results': {'jailbreak': {'filtered': True, 'detected': True}}}, 'code': 'content_filter', 'message': \"The response was filtered due to the prompt triggering Azure OpenAI's content management policy. Please modify your prompt and retry. To learn more about our content filtering policies please read our documentation: \\r\\nhttps://go.microsoft.com/fwlink/?linkid=2198766.\", 'param': 'prompt', 'type': None}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 882/882 [1:52:11<00:00,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num passed: 867\n",
      "Num errors: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vistext_id_to_matplotalt_captions = np.load(\"./vistext_test_id_to_matplotalt_captions.npy\", allow_pickle=True).item()\n",
    "vistext_id_to_gpt4_table_alt_captions = {} #np.load(\"./vistext_test_id_to_L3_gpt4_table_alt_captions.npy\", allow_pickle=True).item()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "model = \"TURBO\"\n",
    "n_errors = 0\n",
    "n_passed = 0\n",
    "for chart_id in tqdm(vistext_id_to_matplotalt_captions.keys()):\n",
    "    if chart_id not in vistext_id_to_gpt4_table_alt_captions:\n",
    "        #print(chart_id)\n",
    "        try:\n",
    "            mpl_code = vistext_id_to_mpl_code[str(chart_id)]\n",
    "            chart_type = vistext_id_to_chart_type[chart_id]\n",
    "            exec(mpl_code)\n",
    "            # gpt4-turbo\n",
    "            gpt4_table_alt_caption = show_with_api_alt(OPENAI_API_KEY, model=model, methods=[], return_alt=True,\n",
    "                                        desc_level=3, stats=[\"min\", \"max\"], max_color_desc_count=0,\n",
    "                                        use_starter_alt_in_prompt=True, use_azure=True,\n",
    "                                        include_table_in_prompt=True,\n",
    "                                        include_colors=False)\n",
    "            plt.clf()\n",
    "            vistext_id_to_gpt4_table_alt_captions[chart_id] = gpt4_table_alt_caption\n",
    "            np.save(\"./vistext_test_id_to_L3_gpt4_table_alt_captions\", vistext_id_to_gpt4_table_alt_captions)\n",
    "            n_passed += 1\n",
    "            #print(gpt4_table_alt_caption)\n",
    "        except Exception as e:\n",
    "            #raise e\n",
    "            print(chart_id)#, mpl_code)\n",
    "            n_errors += 1\n",
    "            plt.clf()\n",
    "            print(e)\n",
    "\n",
    "print(f\"Num passed: {n_passed}\")\n",
    "print(f\"Num errors: {n_errors}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arkenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
