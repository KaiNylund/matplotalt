{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from rouge_score import rouge_scorer\n",
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.98e148b2f8c4a88aba5037e4e0e90c9fd9ec35dc37a054ded8cfef0fa801ffab.bleurt:Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kai\\anaconda3\\envs\\main\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kai\\anaconda3\\envs\\main\\lib\\site-packages\\bleurt\\score.py:160: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Kai\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\66d40c89ded88d187db3310c752ad6bc55a18f1686c772fd971b1af93164b5f5\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint C:\\Users\\Kai\\.cache\\huggingface\\metrics\\bleurt\\default\\downloads\\extracted\\66d40c89ded88d187db3310c752ad6bc55a18f1686c772fd971b1af93164b5f5\\bleurt-base-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kai\\anaconda3\\envs\\main\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Kai\\anaconda3\\envs\\main\\lib\\site-packages\\bleurt\\lib\\bert_tokenization.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    }
   ],
   "source": [
    "rscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True)\n",
    "bleurt = load(\"bleurt\", module_type=\"metric\", checkpoint=\"bleurt-large-512\")\n",
    "bertscore = load(\"bertscore\")\n",
    "bleu = BLEU()\n",
    "chrf = CHRF()\n",
    "\n",
    "def compute_scores(refs, sample):\n",
    "    ref_scores = defaultdict(list)\n",
    "    for ref in refs:\n",
    "        rouge_scores = rscorer.score(ref, sample)\n",
    "        for rouge_metric, score_result in rouge_scores.items():\n",
    "            ref_scores[f\"{rouge_metric}_p\"].append(score_result.precision)\n",
    "            ref_scores[f\"{rouge_metric}_r\"].append(score_result.recall)\n",
    "            ref_scores[f\"{rouge_metric}_f1\"].append(score_result.fmeasure)\n",
    "        ref_scores[\"bleu\"].append(bleu.corpus_score([sample], [[ref]]).score)\n",
    "        ref_scores[\"chrf\"].append(chrf.corpus_score([sample], [[ref]]).score)\n",
    "        ref_scores[\"bleurt\"].append(bleurt.compute(predictions=[sample], references=[ref])[\"scores\"][0])\n",
    "        bertscores = bertscore.compute(predictions=[sample], references=[ref], lang=\"en\")\n",
    "        ref_scores[\"bertscore_p\"] = bertscores[\"precision\"]\n",
    "        ref_scores[\"bertscore_r\"] = bertscores[\"recall\"]\n",
    "        ref_scores[\"bertscore_f1\"] = bertscores[\"f1\"]\n",
    "    return ref_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/882 [01:05<1:35:27,  6.57s/it]\n",
      "100%|██████████| 882/882 [1:11:27<00:00,  6.78s/it]"
     ]
    }
   ],
   "source": [
    "vistext_id_to_captions = pd.read_json(\"./vistext_eval/vistext_id_to_combined_captions.jsonl\", orient=\"records\", lines=True)\n",
    "vistext_id_to_scores = defaultdict(dict) #np.load(\"./vistext_id_to_scores.npy\", allow_pickle=True).item()\n",
    "pbar = tqdm(total=len(vistext_id_to_captions))\n",
    "def get_caption_scores(row):\n",
    "    refs = row[\"human\"]\n",
    "    for caption_type in [\"heuristic\", \"gpt-4-turbo-L3\", \"gpt-4-turbo-alt-L3\", \"gpt-4-turbo-table-L3\", \"gpt-4-turbo-table-alt-L3\"]:\n",
    "        if caption_type in row and row[caption_type]:\n",
    "            processed_caption = row[caption_type][0]\n",
    "            processed_caption = processed_caption.replace(\"This description was generated by a language model. \", \"\")\n",
    "            #print(caption_type, processed_caption)\n",
    "            #print(\"----------------------------------------------------------\")\n",
    "            vistext_id_to_scores[row[\"image_id\"]][caption_type] = compute_scores(refs, processed_caption)\n",
    "    pbar.update(1)\n",
    "\n",
    "vistext_id_to_captions.apply(get_caption_scores, axis=1)\n",
    "np.save(\"./vistext_id_to_sim_scores\", vistext_id_to_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'dict'>,\n",
      "            {'gpt-4-turbo-L3': {'bertscore_f1': 0.882644063964182,\n",
      "                                'bertscore_p': 0.8704650796730232,\n",
      "                                'bertscore_r': 0.8953872045962449,\n",
      "                                'bleu': 14.14066381414324,\n",
      "                                'bleurt': -0.14390061662686388,\n",
      "                                'chrf': 46.430975596845954,\n",
      "                                'rouge1_f1': 0.4636736219061632,\n",
      "                                'rouge1_p': 0.3759233302022657,\n",
      "                                'rouge1_r': 0.6377347115494284,\n",
      "                                'rouge2_f1': 0.2260586446410901,\n",
      "                                'rouge2_p': 0.1821134742350561,\n",
      "                                'rouge2_r': 0.31470937233073093,\n",
      "                                'rougeL_f1': 0.32315676028608786,\n",
      "                                'rougeL_p': 0.2609146964897651,\n",
      "                                'rougeL_r': 0.44769307784171214,\n",
      "                                'rougeLsum_f1': 0.32481832432467816,\n",
      "                                'rougeLsum_p': 0.26221369736367856,\n",
      "                                'rougeLsum_r': 0.45011235010610634},\n",
      "             'gpt-4-turbo-alt-L3': {'bertscore_f1': 0.8875464822052557,\n",
      "                                    'bertscore_p': 0.8735928290547902,\n",
      "                                    'bertscore_r': 0.9021586196647193,\n",
      "                                    'bleu': 15.660813053410196,\n",
      "                                    'bleurt': -0.0944906171078084,\n",
      "                                    'chrf': 49.22086354607222,\n",
      "                                    'rouge1_f1': 0.4836565263543092,\n",
      "                                    'rouge1_p': 0.38975881296159537,\n",
      "                                    'rouge1_r': 0.6711167786834155,\n",
      "                                    'rouge2_f1': 0.259739815459184,\n",
      "                                    'rouge2_p': 0.20783708637543252,\n",
      "                                    'rouge2_r': 0.36515739321050683,\n",
      "                                    'rougeL_f1': 0.3500276351536176,\n",
      "                                    'rougeL_p': 0.2808176021132274,\n",
      "                                    'rougeL_r': 0.4896113761698571,\n",
      "                                    'rougeLsum_f1': 0.3498711761241361,\n",
      "                                    'rougeLsum_p': 0.2807215838175137,\n",
      "                                    'rougeLsum_r': 0.48923663916804433},\n",
      "             'gpt-4-turbo-table-L3': {'bertscore_f1': 0.8825184934932176,\n",
      "                                      'bertscore_p': 0.8683395740257895,\n",
      "                                      'bertscore_r': 0.8973889156042786,\n",
      "                                      'bleu': 13.463786240685417,\n",
      "                                      'bleurt': -0.13703070614425286,\n",
      "                                      'chrf': 46.60697966377538,\n",
      "                                      'rouge1_f1': 0.4606288617480206,\n",
      "                                      'rouge1_p': 0.3651008007876437,\n",
      "                                      'rouge1_r': 0.6600952330532887,\n",
      "                                      'rouge2_f1': 0.22350847820005215,\n",
      "                                      'rouge2_p': 0.17598344046764264,\n",
      "                                      'rouge2_r': 0.3246531091326633,\n",
      "                                      'rougeL_f1': 0.3196975647513145,\n",
      "                                      'rougeL_p': 0.252151160374873,\n",
      "                                      'rougeL_r': 0.4623113714464718,\n",
      "                                      'rougeLsum_f1': 0.32180613796188023,\n",
      "                                      'rougeLsum_p': 0.2537782672731184,\n",
      "                                      'rougeLsum_r': 0.46543149776173104},\n",
      "             'gpt-4-turbo-table-alt-L3': {'bertscore_f1': 0.8864635874655833,\n",
      "                                          'bertscore_p': 0.8712966599541414,\n",
      "                                          'bertscore_r': 0.9023869010816395,\n",
      "                                          'bleu': 15.022985439805622,\n",
      "                                          'bleurt': -0.09998064045625997,\n",
      "                                          'chrf': 48.938805514862295,\n",
      "                                          'rouge1_f1': 0.4754977463297677,\n",
      "                                          'rouge1_p': 0.37761132056298113,\n",
      "                                          'rouge1_r': 0.6768474572065769,\n",
      "                                          'rouge2_f1': 0.2550244448094262,\n",
      "                                          'rouge2_p': 0.20105417224520922,\n",
      "                                          'rouge2_r': 0.36836385253801696,\n",
      "                                          'rougeL_f1': 0.3431509812446006,\n",
      "                                          'rougeL_p': 0.2712622777117092,\n",
      "                                          'rougeL_r': 0.49262455850835407,\n",
      "                                          'rougeLsum_f1': 0.3450810160585671,\n",
      "                                          'rougeLsum_p': 0.27273547737043496,\n",
      "                                          'rougeLsum_r': 0.49555183522341806},\n",
      "             'heuristic': {'bertscore_f1': 0.8850457179708545,\n",
      "                           'bertscore_p': 0.8752519416025166,\n",
      "                           'bertscore_r': 0.8952865943211277,\n",
      "                           'bleu': 15.569139111644427,\n",
      "                           'bleurt': -0.152631374232207,\n",
      "                           'chrf': 45.8869249613938,\n",
      "                           'rouge1_f1': 0.5459723205624998,\n",
      "                           'rouge1_p': 0.5292213915398621,\n",
      "                           'rouge1_r': 0.5837083229341858,\n",
      "                           'rouge2_f1': 0.32513188748808014,\n",
      "                           'rouge2_p': 0.31321984679763487,\n",
      "                           'rouge2_r': 0.35037771372541904,\n",
      "                           'rougeL_f1': 0.3956005620955884,\n",
      "                           'rougeL_p': 0.3819810584111435,\n",
      "                           'rougeL_r': 0.4249977302734329,\n",
      "                           'rougeLsum_f1': 0.3956005620955884,\n",
      "                           'rougeLsum_p': 0.3819810584111435,\n",
      "                           'rougeLsum_r': 0.4249977302734329}})\n"
     ]
    }
   ],
   "source": [
    "vistext_id_to_scores = np.load(\"./vistext_id_to_sim_scores.npy\", allow_pickle=True).item()\n",
    "combined_method_scores = {}\n",
    "for caption_type in [\"heuristic\", \"gpt-4-turbo-L3\", \"gpt-4-turbo-alt-L3\", \"gpt-4-turbo-table-L3\", \"gpt-4-turbo-table-alt-L3\"]:\n",
    "    combined_method_scores[caption_type] = defaultdict(list)\n",
    "for image_id, caption_scores in vistext_id_to_scores.items():\n",
    "    for caption_type, scores_dict in caption_scores.items():\n",
    "        for score_type, scores in scores_dict.items():\n",
    "            combined_method_scores[caption_type][score_type].extend(scores)\n",
    "caption_type_to_avg_scores = defaultdict(dict)\n",
    "for caption_type, caption_scores in combined_method_scores.items():\n",
    "    for score_type, scores in caption_scores.items():\n",
    "        caption_type_to_avg_scores[caption_type][score_type] = np.mean(scores)\n",
    "\n",
    "pprint(caption_type_to_avg_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
